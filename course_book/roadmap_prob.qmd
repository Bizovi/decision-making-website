---
author:
  - name: Mihai Bizovi
    id: mb
    degrees: 
    - "VP of Decision Science"

format:
  html:
    toc-location: left

title: "Module II: Probability and Statistics"
---



There are so many pitfalls in statistics and many of them come from a misunderstanding about the nature of statistical inference, a mechanical application of methods, and an insufficient grasp of fundamentals. I prefer to fill in the gaps with **stories** and **simulations**, however, in some cases the mathematical formalism and abstractions can't be avoided and actually helps understanding.


::: {.column-margin}

I think that the best way to start understanding inferential statistics is Daniel Lakens' book on "Improving your statistical inferences", combined with another resource like Speegle's "Probability, Statistics, and Data" for a deep-dive on technicalities.

:::

Therefore, fundamental -- doesn't mean easy, nor basic, nor trivial. Most courses make you solve puzzles, but I ask you to appropriately define, justify, and apply the choice of method and tool in the context of business applications.


::: {.column-page-inset-right}

|   | Lecture Agenda  | Key Ideas  | Case Studies / Activities |
|---|------------------|----------------------------------|---------------------------|
| 1* | Combinatorics. Sampling & Urn Models | Sampling with and without replacement, multiplication rule, naive $\mathbb{P}$, probability trees | Birthday Paradox simulation, Why bootstrap works |
| 2 | Probability Triple. Random Variables. What is a model? | collectivity, population, sample; estimand, estimator, estimation; $(\Omega, \mathcal{F}, \mathbb{P})$, $X$ r.v., $H(y | F(u), \phi(y, u))$| Probability vs Statistics. $\mathcal{H}$, Process models, Statistical models, Inference |
| 3 | **Stories behind distributions** | Binomial, Poisson, Mixtures, $N(\mu, \sigma)$, $\chi^2_k$, $t_k$, F, Beta, Gamma, Exponential, NBin, HGeom | couples showing up to safari, arrival times, basketball shots, hot hand |
| 4* | Conditioning and Bayes Rule. Likelihood Ratios | Updating prior beliefs, Bayesian vs frequentist interpretation of probability. Graphical models | Monty Hall, Simpsons' Paradox, Football Spreads, Medical testing |
| 5* | **CLT** and LLNs. Convergence types. Estimator properties | Never forget about sample size. Why simulation works? Limitation: rare events, fat tails, mixtures, non-iid | The most dangerous equation: US schools, gold coins. Simulation |
| 6* | Fisher Information. **Bias-Variance** tradeoff | Efficiency, bias, James-Stein paradox and the curse of dimensionality. Rao-Cramer. Likelihood approach | Overfitting, underfitting, and mis-specification. Bootstrap, simulations |
| 7* | Neyman-Pearson frequentism. Long-run action | Type I, II errors, confint, p-value, PPV, effect sizes, **power analysis, range predictions**, $H_0$, $H_A$ | How to ask better questions. Stahel's relevance, Interval $\mathcal{H}$ testing. Default action  |
| 8 | Frequentist vs Likelihood vs Bayesian inference | Popperian philosophical roots, practical agreements, strengths and weaknesses | Discussion on practical interpretation: path of action vs devotion vs belief  |
| 9 | Dead Salmon Experiment. Replication Crisis | multiple testing, harking, snooping, publication bias, open science, underpowered studies | Examination of controversies in medicine, psychology, and social science  |

:::

<br>

## Python/R Computational Toolbox

In order to make the most out of the three modules, we need to be skilled (or at least competent) programmers, from the perspective of data science. It is a skill which can be developed independently -- I give a few recommendations in the introduction (prerequisites section).

::: {.column-margin}

In this course I heavily rely on the principles of reproducible research, which have 3 key aspects: data, computational environment, and code.

:::

A second aspect that we need for the programming part not to slow us down and stand in the way, is to have a good, pleasant, and reliable development environment setup. Here is a starting, non-exhaustive list of tools you will need. 

For Windows 11+ users, I strongly recommend you use WSLII -- and get familiar with the command line & linux. Between R and Python, I choose technologies which make it easy to draw parallels and transition from one to another.

::: {.callout-tip}
## For R (v4.4.2)

- RStudio as our main IDE
- Quarto for literate programming
- git & github
- renv for managing environments
- database: duckdb (analytical, in-process)
- data wrangling: tidyverse, data.table (bigger data), arrow
- data visualization: ggplot, plotly
- interactive applications: shiny
- APIs: plumbr

R has many gotchas, which is the main reason that makes the language hard. Therefore, we need to some additional concepts in R, especially functional programming and understanding the S3 object system. Tidyverse is an important ecosystem which tries to solve a lot of the issues in base R.
:::

::: {.callout-tip}
## For Python (v3.10.x)

- VScode as our main IDE
- Jupyter Notebooks or Quarto for literate programming
- git & github
- uv (recommended) or conda for managing environments
- database: duckdb (analytical, in-process), sqlite (transactional, in-process)
- data wrangling: pandas 2.0, pypolars (bigger data), arrow
- interactive applications: streamlit, shiny, or dash
- APIs: fastapi

:::